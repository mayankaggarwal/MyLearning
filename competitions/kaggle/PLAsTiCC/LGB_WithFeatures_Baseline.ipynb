{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ogrellier/plasticc-in-a-kernel-meta-and-data/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#9575cd'>1. Importing Packages and Data</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = 'D:/Competitions/Data/PLAsTiCC_Challengle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train = pd.read_csv(os.path.join(folderPath,'training_set_metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(folderPath,'training_set.csv.zip'),compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger():\n",
    "    logger_ = logging.getLogger('main')\n",
    "    logger_.setLevel(logging.DEBUG)\n",
    "    fh = logging.FileHandler('simple_lightgbm.log')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('[%(levelname)s]%(asctime)s:%(name)s:%(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "    # add the handlers to the logger\n",
    "    logger_.addHandler(fh)\n",
    "    logger_.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger():\n",
    "    return logging.getLogger('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#9575cd'>2. Data Exploration and Manipulation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#00b8d4\">2.1 Missing value treatment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#00b8d4\">2.2 Outlier Detection and treatment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#00b8d4\">2.3 Oversampling the minority class</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#00b8d4\">2.4 Data type assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#00b8d4\">2.5 Label Exploration</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#9575cd'>3. Feature Engineering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['flux_ratio_sq'] = np.power(train['flux']/train['flux_err'],2.0)\n",
    "train['flux_by_flux_ratio_sq'] = train['flux']*train['flux_ratio_sq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregations():\n",
    "    return {\n",
    "        # Dropped mjd aggregations on CPMP advice\n",
    "        # see https://www.kaggle.com/c/PLAsTiCC-2018/discussion/69696\n",
    "        # 'mjd': ['min', 'max', 'size'],\n",
    "        'passband': ['mean', 'std', 'var'],  # ''min', 'max', 'mean', 'median', 'std'],\n",
    "        'flux': ['min', 'max', 'mean', 'median', 'std'],\n",
    "        'flux_err': ['min', 'max', 'mean', 'median', 'std'],\n",
    "        'detected': ['mean'],  # ''min', 'max', 'mean', 'median', 'std'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = get_aggregations()\n",
    "aggs['flux_ratio_sq'] = ['sum']\n",
    "aggs['flux_by_flux_ratio_sq'] = ['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train = train.groupby('object_id').agg(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_columns(aggs):\n",
    "    return [k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "new_columns = get_new_columns(aggs)\n",
    "agg_train.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passband_mean</th>\n",
       "      <th>passband_std</th>\n",
       "      <th>passband_var</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>flux_err_median</th>\n",
       "      <th>flux_err_std</th>\n",
       "      <th>detected_mean</th>\n",
       "      <th>flux_ratio_sq_sum</th>\n",
       "      <th>flux_by_flux_ratio_sq_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2.457386</td>\n",
       "      <td>1.720797</td>\n",
       "      <td>2.961142</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-123.096998</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>394.109851</td>\n",
       "      <td>2.130510</td>\n",
       "      <td>12.845472</td>\n",
       "      <td>4.482743</td>\n",
       "      <td>3.835269</td>\n",
       "      <td>1.744747</td>\n",
       "      <td>0.946023</td>\n",
       "      <td>2.929669e+06</td>\n",
       "      <td>-9.601766e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.746056</td>\n",
       "      <td>3.048711</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873033</td>\n",
       "      <td>6.471144</td>\n",
       "      <td>0.639458</td>\n",
       "      <td>9.115748</td>\n",
       "      <td>2.359620</td>\n",
       "      <td>1.998217</td>\n",
       "      <td>1.509888</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>5.886068e+03</td>\n",
       "      <td>-2.875087e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2.336364</td>\n",
       "      <td>1.758750</td>\n",
       "      <td>3.093203</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>8.022239</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>11.281384</td>\n",
       "      <td>2.471061</td>\n",
       "      <td>1.990851</td>\n",
       "      <td>1.721134</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>4.124452e+03</td>\n",
       "      <td>1.046502e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2.378917</td>\n",
       "      <td>1.747328</td>\n",
       "      <td>3.053154</td>\n",
       "      <td>-15.494463</td>\n",
       "      <td>220.795212</td>\n",
       "      <td>8.909206</td>\n",
       "      <td>1.035895</td>\n",
       "      <td>27.558208</td>\n",
       "      <td>0.567170</td>\n",
       "      <td>55.892746</td>\n",
       "      <td>2.555576</td>\n",
       "      <td>1.819875</td>\n",
       "      <td>3.537324</td>\n",
       "      <td>0.173789</td>\n",
       "      <td>9.416165e+04</td>\n",
       "      <td>1.439125e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2.457386</td>\n",
       "      <td>1.720797</td>\n",
       "      <td>2.961142</td>\n",
       "      <td>-16.543753</td>\n",
       "      <td>143.600189</td>\n",
       "      <td>7.145702</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>20.051722</td>\n",
       "      <td>0.695277</td>\n",
       "      <td>11.383690</td>\n",
       "      <td>2.753004</td>\n",
       "      <td>2.214854</td>\n",
       "      <td>1.933837</td>\n",
       "      <td>0.173295</td>\n",
       "      <td>3.432418e+04</td>\n",
       "      <td>3.015599e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           passband_mean  passband_std  passband_var     flux_min    flux_max  \\\n",
       "object_id                                                                       \n",
       "615             2.457386      1.720797      2.961142 -1100.440063  660.626343   \n",
       "713             2.400000      1.746056      3.048711   -14.735178   14.770886   \n",
       "730             2.336364      1.758750      3.093203   -19.159811   47.310059   \n",
       "745             2.378917      1.747328      3.053154   -15.494463  220.795212   \n",
       "1124            2.457386      1.720797      2.961142   -16.543753  143.600189   \n",
       "\n",
       "            flux_mean  flux_median    flux_std  flux_err_min  flux_err_max  \\\n",
       "object_id                                                                    \n",
       "615       -123.096998   -89.477524  394.109851      2.130510     12.845472   \n",
       "713         -1.423351    -0.873033    6.471144      0.639458      9.115748   \n",
       "730          2.267434     0.409172    8.022239      0.695106     11.281384   \n",
       "745          8.909206     1.035895   27.558208      0.567170     55.892746   \n",
       "1124         7.145702     1.141288   20.051722      0.695277     11.383690   \n",
       "\n",
       "           flux_err_mean  flux_err_median  flux_err_std  detected_mean  \\\n",
       "object_id                                                                \n",
       "615             4.482743         3.835269      1.744747       0.946023   \n",
       "713             2.359620         1.998217      1.509888       0.171429   \n",
       "730             2.471061         1.990851      1.721134       0.069697   \n",
       "745             2.555576         1.819875      3.537324       0.173789   \n",
       "1124            2.753004         2.214854      1.933837       0.173295   \n",
       "\n",
       "           flux_ratio_sq_sum  flux_by_flux_ratio_sq_sum  \n",
       "object_id                                                \n",
       "615             2.929669e+06              -9.601766e+08  \n",
       "713             5.886068e+03              -2.875087e+04  \n",
       "730             4.124452e+03               1.046502e+05  \n",
       "745             9.416165e+04               1.439125e+07  \n",
       "1124            3.432418e+04               3.015599e+06  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passband_mean</th>\n",
       "      <th>passband_std</th>\n",
       "      <th>passband_var</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>flux_err_median</th>\n",
       "      <th>flux_err_std</th>\n",
       "      <th>detected_mean</th>\n",
       "      <th>flux_ratio_sq_sum</th>\n",
       "      <th>flux_by_flux_ratio_sq_sum</th>\n",
       "      <th>flux_diff</th>\n",
       "      <th>flux_dif2</th>\n",
       "      <th>flux_w_mean</th>\n",
       "      <th>flux_dif3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2.457386</td>\n",
       "      <td>1.720797</td>\n",
       "      <td>2.961142</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-123.096998</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>394.109851</td>\n",
       "      <td>2.130510</td>\n",
       "      <td>12.845472</td>\n",
       "      <td>4.482743</td>\n",
       "      <td>3.835269</td>\n",
       "      <td>1.744747</td>\n",
       "      <td>0.946023</td>\n",
       "      <td>2.929669e+06</td>\n",
       "      <td>-9.601766e+08</td>\n",
       "      <td>1761.066406</td>\n",
       "      <td>-14.306331</td>\n",
       "      <td>-327.742307</td>\n",
       "      <td>-5.373326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.746056</td>\n",
       "      <td>3.048711</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873033</td>\n",
       "      <td>6.471144</td>\n",
       "      <td>0.639458</td>\n",
       "      <td>9.115748</td>\n",
       "      <td>2.359620</td>\n",
       "      <td>1.998217</td>\n",
       "      <td>1.509888</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>5.886068e+03</td>\n",
       "      <td>-2.875087e+04</td>\n",
       "      <td>29.506064</td>\n",
       "      <td>-20.730002</td>\n",
       "      <td>-4.884564</td>\n",
       "      <td>-6.040676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2.336364</td>\n",
       "      <td>1.758750</td>\n",
       "      <td>3.093203</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>8.022239</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>11.281384</td>\n",
       "      <td>2.471061</td>\n",
       "      <td>1.990851</td>\n",
       "      <td>1.721134</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>4.124452e+03</td>\n",
       "      <td>1.046502e+05</td>\n",
       "      <td>66.469870</td>\n",
       "      <td>29.315018</td>\n",
       "      <td>25.373110</td>\n",
       "      <td>2.619697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2.378917</td>\n",
       "      <td>1.747328</td>\n",
       "      <td>3.053154</td>\n",
       "      <td>-15.494463</td>\n",
       "      <td>220.795212</td>\n",
       "      <td>8.909206</td>\n",
       "      <td>1.035895</td>\n",
       "      <td>27.558208</td>\n",
       "      <td>0.567170</td>\n",
       "      <td>55.892746</td>\n",
       "      <td>2.555576</td>\n",
       "      <td>1.819875</td>\n",
       "      <td>3.537324</td>\n",
       "      <td>0.173789</td>\n",
       "      <td>9.416165e+04</td>\n",
       "      <td>1.439125e+07</td>\n",
       "      <td>236.289675</td>\n",
       "      <td>26.521968</td>\n",
       "      <td>152.835617</td>\n",
       "      <td>1.546038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2.457386</td>\n",
       "      <td>1.720797</td>\n",
       "      <td>2.961142</td>\n",
       "      <td>-16.543753</td>\n",
       "      <td>143.600189</td>\n",
       "      <td>7.145702</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>20.051722</td>\n",
       "      <td>0.695277</td>\n",
       "      <td>11.383690</td>\n",
       "      <td>2.753004</td>\n",
       "      <td>2.214854</td>\n",
       "      <td>1.933837</td>\n",
       "      <td>0.173295</td>\n",
       "      <td>3.432418e+04</td>\n",
       "      <td>3.015599e+06</td>\n",
       "      <td>160.143942</td>\n",
       "      <td>22.411225</td>\n",
       "      <td>87.856390</td>\n",
       "      <td>1.822792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           passband_mean  passband_std  passband_var     flux_min    flux_max  \\\n",
       "object_id                                                                       \n",
       "615             2.457386      1.720797      2.961142 -1100.440063  660.626343   \n",
       "713             2.400000      1.746056      3.048711   -14.735178   14.770886   \n",
       "730             2.336364      1.758750      3.093203   -19.159811   47.310059   \n",
       "745             2.378917      1.747328      3.053154   -15.494463  220.795212   \n",
       "1124            2.457386      1.720797      2.961142   -16.543753  143.600189   \n",
       "\n",
       "            flux_mean  flux_median    flux_std  flux_err_min  flux_err_max  \\\n",
       "object_id                                                                    \n",
       "615       -123.096998   -89.477524  394.109851      2.130510     12.845472   \n",
       "713         -1.423351    -0.873033    6.471144      0.639458      9.115748   \n",
       "730          2.267434     0.409172    8.022239      0.695106     11.281384   \n",
       "745          8.909206     1.035895   27.558208      0.567170     55.892746   \n",
       "1124         7.145702     1.141288   20.051722      0.695277     11.383690   \n",
       "\n",
       "           flux_err_mean  flux_err_median  flux_err_std  detected_mean  \\\n",
       "object_id                                                                \n",
       "615             4.482743         3.835269      1.744747       0.946023   \n",
       "713             2.359620         1.998217      1.509888       0.171429   \n",
       "730             2.471061         1.990851      1.721134       0.069697   \n",
       "745             2.555576         1.819875      3.537324       0.173789   \n",
       "1124            2.753004         2.214854      1.933837       0.173295   \n",
       "\n",
       "           flux_ratio_sq_sum  flux_by_flux_ratio_sq_sum    flux_diff  \\\n",
       "object_id                                                              \n",
       "615             2.929669e+06              -9.601766e+08  1761.066406   \n",
       "713             5.886068e+03              -2.875087e+04    29.506064   \n",
       "730             4.124452e+03               1.046502e+05    66.469870   \n",
       "745             9.416165e+04               1.439125e+07   236.289675   \n",
       "1124            3.432418e+04               3.015599e+06   160.143942   \n",
       "\n",
       "           flux_dif2  flux_w_mean  flux_dif3  \n",
       "object_id                                     \n",
       "615       -14.306331  -327.742307  -5.373326  \n",
       "713       -20.730002    -4.884564  -6.040676  \n",
       "730        29.315018    25.373110   2.619697  \n",
       "745        26.521968   152.835617   1.546038  \n",
       "1124       22.411225    87.856390   1.822792  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_features_to_agg(df):\n",
    "    # CPMP using the following feature was really silliy :)\n",
    "    # df['mjd_diff'] = df['mjd_max'] - df['mjd_min']\n",
    "    # see https://www.kaggle.com/c/PLAsTiCC-2018/discussion/69696\n",
    "    \n",
    "    # The others may be useful\n",
    "    df['flux_diff'] = df['flux_max'] - df['flux_min']\n",
    "    df['flux_dif2'] = (df['flux_max'] - df['flux_min']) / df['flux_mean']\n",
    "    df['flux_w_mean'] = df['flux_by_flux_ratio_sq_sum'] / df['flux_ratio_sq_sum']\n",
    "    df['flux_dif3'] = (df['flux_max'] - df['flux_min']) / df['flux_w_mean']\n",
    "\n",
    "    # del df['mjd_max'], df['mjd_min']\n",
    "\n",
    "    return df\n",
    "\n",
    "agg_train = add_features_to_agg(df=agg_train)\n",
    "agg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>349.046051</td>\n",
       "      <td>-61.943836</td>\n",
       "      <td>320.796530</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>53.085938</td>\n",
       "      <td>-27.784405</td>\n",
       "      <td>223.525509</td>\n",
       "      <td>-54.460748</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8181</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>45.4063</td>\n",
       "      <td>0.007</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>33.574219</td>\n",
       "      <td>-6.579593</td>\n",
       "      <td>170.455585</td>\n",
       "      <td>-61.548219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>40.2561</td>\n",
       "      <td>0.021</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>-45.586655</td>\n",
       "      <td>328.254458</td>\n",
       "      <td>-68.969298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>352.711273</td>\n",
       "      <td>-63.823658</td>\n",
       "      <td>316.922299</td>\n",
       "      <td>-51.059403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>0.024</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id          ra       decl       gal_l      gal_b  ddf  \\\n",
       "0        615  349.046051 -61.943836  320.796530 -51.753706    1   \n",
       "1        713   53.085938 -27.784405  223.525509 -54.460748    1   \n",
       "2        730   33.574219  -6.579593  170.455585 -61.548219    1   \n",
       "3        745    0.189873 -45.586655  328.254458 -68.969298    1   \n",
       "4       1124  352.711273 -63.823658  316.922299 -51.059403    1   \n",
       "\n",
       "   hostgal_specz  hostgal_photoz  hostgal_photoz_err  distmod  mwebv  target  \n",
       "0         0.0000          0.0000              0.0000      NaN  0.017      92  \n",
       "1         1.8181          1.6267              0.2552  45.4063  0.007      88  \n",
       "2         0.2320          0.2262              0.0157  40.2561  0.021      42  \n",
       "3         0.3037          0.2813              1.1523  40.7951  0.007      90  \n",
       "4         0.1934          0.2415              0.0176  40.4166  0.024      90  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = agg_train.reset_index().merge(\n",
    "    right=meta_train,\n",
    "    how='outer',\n",
    "    on='object_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full_train['target']\n",
    "del full_train['target']\n",
    "del full_train['object_id'], full_train['hostgal_specz']  # , full_train['distmod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = full_train.mean(axis=0)\n",
    "full_train.fillna(train_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:13:13,247:main:Index(['passband_mean', 'passband_std', 'passband_var', 'flux_min', 'flux_max',\n",
      "       'flux_mean', 'flux_median', 'flux_std', 'flux_err_min', 'flux_err_max',\n",
      "       'flux_err_mean', 'flux_err_median', 'flux_err_std', 'detected_mean',\n",
      "       'flux_ratio_sq_sum', 'flux_by_flux_ratio_sq_sum', 'flux_diff',\n",
      "       'flux_dif2', 'flux_w_mean', 'flux_dif3', 'ra', 'decl', 'gal_l', 'gal_b',\n",
      "       'ddf', 'hostgal_photoz', 'hostgal_photoz_err', 'distmod', 'mwebv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "get_logger().info(full_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_classifiers(full_train=None, y=None):\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    clfs = []\n",
    "    importances = pd.DataFrame()\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 14,\n",
    "        'metric': 'multi_logloss',\n",
    "        'learning_rate': 0.03,\n",
    "        'subsample': .9,\n",
    "        'colsample_bytree': .7,\n",
    "        'reg_alpha': .01,\n",
    "        'reg_lambda': .01,\n",
    "        'min_split_gain': 0.01,\n",
    "        'min_child_weight': 10,\n",
    "        'n_estimators': 1000,\n",
    "        'silent': -1,\n",
    "        'verbose': -1,\n",
    "        'max_depth': 3\n",
    "    }\n",
    "    \n",
    "    # Compute weights\n",
    "    w = y.value_counts()\n",
    "    weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "        \n",
    "    oof_preds = np.zeros((len(full_train), np.unique(y).shape[0]))\n",
    "    for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "        trn_x, trn_y = full_train.iloc[trn_], y.iloc[trn_]\n",
    "        val_x, val_y = full_train.iloc[val_], y.iloc[val_]\n",
    "\n",
    "        clf = lgb.LGBMClassifier(**lgb_params)\n",
    "        clf.fit(\n",
    "            trn_x, trn_y,\n",
    "            eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "            eval_metric=lgb_multi_weighted_logloss,\n",
    "            verbose=100,\n",
    "            early_stopping_rounds=50,\n",
    "            sample_weight=trn_y.map(weights)\n",
    "        )\n",
    "        oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "        get_logger().info(multi_weighted_logloss(val_y, clf.predict_proba(val_x, num_iteration=clf.best_iteration_)))\n",
    "\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = full_train.columns\n",
    "        imp_df['gain'] = clf.feature_importances_\n",
    "        imp_df['fold'] = fold_ + 1\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "        clfs.append(clf)\n",
    "\n",
    "    get_logger().info('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(y_true=y, y_preds=oof_preds))\n",
    "\n",
    "    return clfs, importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.980512\ttraining's wloss: 0.989184\tvalid_1's multi_logloss: 1.32472\tvalid_1's wloss: 1.15104\n",
      "[200]\ttraining's multi_logloss: 0.747879\ttraining's wloss: 0.755336\tvalid_1's multi_logloss: 1.14974\tvalid_1's wloss: 0.995227\n",
      "[300]\ttraining's multi_logloss: 0.634578\ttraining's wloss: 0.641895\tvalid_1's multi_logloss: 1.08111\tvalid_1's wloss: 0.945513\n",
      "[400]\ttraining's multi_logloss: 0.558236\ttraining's wloss: 0.565497\tvalid_1's multi_logloss: 1.04432\tvalid_1's wloss: 0.928274\n",
      "[500]\ttraining's multi_logloss: 0.500964\ttraining's wloss: 0.507886\tvalid_1's multi_logloss: 1.01964\tvalid_1's wloss: 0.923751\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's multi_logloss: 0.49852\ttraining's wloss: 0.505436\tvalid_1's multi_logloss: 1.01861\tvalid_1's wloss: 0.923745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:17:04,617:main:0.9237452012851757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.987605\ttraining's wloss: 0.998514\tvalid_1's multi_logloss: 1.2965\tvalid_1's wloss: 1.148\n",
      "[200]\ttraining's multi_logloss: 0.751567\ttraining's wloss: 0.761667\tvalid_1's multi_logloss: 1.11491\tvalid_1's wloss: 1.00134\n",
      "[300]\ttraining's multi_logloss: 0.63681\ttraining's wloss: 0.645433\tvalid_1's multi_logloss: 1.04848\tvalid_1's wloss: 0.985734\n",
      "Early stopping, best iteration is:\n",
      "[269]\ttraining's multi_logloss: 0.666565\ttraining's wloss: 0.675538\tvalid_1's multi_logloss: 1.06366\tvalid_1's wloss: 0.984059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:17:17,190:main:0.9840588857290515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.977148\ttraining's wloss: 0.987429\tvalid_1's multi_logloss: 1.32644\tvalid_1's wloss: 1.12946\n",
      "[200]\ttraining's multi_logloss: 0.745459\ttraining's wloss: 0.754049\tvalid_1's multi_logloss: 1.14058\tvalid_1's wloss: 0.951627\n",
      "[300]\ttraining's multi_logloss: 0.631078\ttraining's wloss: 0.63837\tvalid_1's multi_logloss: 1.06812\tvalid_1's wloss: 0.904318\n",
      "[400]\ttraining's multi_logloss: 0.552048\ttraining's wloss: 0.558322\tvalid_1's multi_logloss: 1.02638\tvalid_1's wloss: 0.884137\n",
      "[500]\ttraining's multi_logloss: 0.4945\ttraining's wloss: 0.500043\tvalid_1's multi_logloss: 0.997239\tvalid_1's wloss: 0.878802\n",
      "Early stopping, best iteration is:\n",
      "[530]\ttraining's multi_logloss: 0.479664\ttraining's wloss: 0.485031\tvalid_1's multi_logloss: 0.989757\tvalid_1's wloss: 0.877091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:17:38,029:main:0.877090668094761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.98622\ttraining's wloss: 0.99423\tvalid_1's multi_logloss: 1.306\tvalid_1's wloss: 1.12543\n",
      "[200]\ttraining's multi_logloss: 0.750976\ttraining's wloss: 0.758081\tvalid_1's multi_logloss: 1.12378\tvalid_1's wloss: 0.967182\n",
      "[300]\ttraining's multi_logloss: 0.631919\ttraining's wloss: 0.638458\tvalid_1's multi_logloss: 1.05548\tvalid_1's wloss: 0.942969\n",
      "Early stopping, best iteration is:\n",
      "[297]\ttraining's multi_logloss: 0.634724\ttraining's wloss: 0.641209\tvalid_1's multi_logloss: 1.05713\tvalid_1's wloss: 0.942902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:17:50,532:main:0.9429024010222529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.988632\ttraining's wloss: 0.995491\tvalid_1's multi_logloss: 1.29942\tvalid_1's wloss: 1.13589\n",
      "[200]\ttraining's multi_logloss: 0.754485\ttraining's wloss: 0.761123\tvalid_1's multi_logloss: 1.11597\tvalid_1's wloss: 0.966092\n",
      "[300]\ttraining's multi_logloss: 0.636693\ttraining's wloss: 0.642817\tvalid_1's multi_logloss: 1.0429\tvalid_1's wloss: 0.922464\n",
      "[400]\ttraining's multi_logloss: 0.556925\ttraining's wloss: 0.562543\tvalid_1's multi_logloss: 1.00527\tvalid_1's wloss: 0.914064\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttraining's multi_logloss: 0.569406\ttraining's wloss: 0.575195\tvalid_1's multi_logloss: 1.01018\tvalid_1's wloss: 0.912755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:18:08,533:main:0.9127550309142146\n",
      "[INFO]2018-12-09 19:18:08,552:main:MULTI WEIGHTED LOG LOSS : 0.92817 \n"
     ]
    }
   ],
   "source": [
    "clfs, importances = train_classifiers(full_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_importances(importances_):\n",
    "    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n",
    "    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    sns.barplot(x='gain', y='feature', data=importances_.sort_values('mean_gain', ascending=False))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_importances(importances_=importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chunk(df_, clfs_, meta_, features, train_mean):\n",
    "\n",
    "    df_['flux_ratio_sq'] = np.power(df_['flux'] / df_['flux_err'], 2.0)\n",
    "    df_['flux_by_flux_ratio_sq'] = df_['flux'] * df_['flux_ratio_sq']\n",
    "\n",
    "    # Group by object id\n",
    "    aggs = get_aggregations()\n",
    "\n",
    "    aggs = get_aggregations()\n",
    "    aggs['flux_ratio_sq'] = ['sum']\n",
    "    aggs['flux_by_flux_ratio_sq'] = ['sum']\n",
    "\n",
    "    new_columns = get_new_columns(aggs)\n",
    "\n",
    "    agg_ = df_.groupby('object_id').agg(aggs)\n",
    "    agg_.columns = new_columns\n",
    "\n",
    "    agg_ = add_features_to_agg(df=agg_)\n",
    "\n",
    "    # Merge with meta data\n",
    "    full_test = agg_.reset_index().merge(\n",
    "        right=meta_,\n",
    "        how='left',\n",
    "        on='object_id'\n",
    "    )\n",
    "\n",
    "    full_test = full_test.fillna(train_mean)\n",
    "    # Make predictions\n",
    "    preds_ = None\n",
    "    for clf in clfs_:\n",
    "        if preds_ is None:\n",
    "            preds_ = clf.predict_proba(full_test[features]) / len(clfs_)\n",
    "        else:\n",
    "            preds_ += clf.predict_proba(full_test[features]) / len(clfs_)\n",
    "\n",
    "    # Compute preds_99 as the proba of class not being any of the others\n",
    "    # preds_99 = 0.1 gives 1.769\n",
    "    preds_99 = np.ones(preds_.shape[0])\n",
    "    for i in range(preds_.shape[1]):\n",
    "        preds_99 *= (1 - preds_[:, i])\n",
    "\n",
    "    # Create DataFrame from predictions\n",
    "    preds_df_ = pd.DataFrame(preds_, columns=['class_' + str(s) for s in clfs_[0].classes_])\n",
    "    preds_df_['object_id'] = full_test['object_id']\n",
    "    preds_df_['class_99'] = 0.14 * preds_99 / np.mean(preds_99) \n",
    "\n",
    "    print(preds_df_['class_99'].mean())\n",
    "\n",
    "    del agg_, full_test, preds_\n",
    "    gc.collect()\n",
    "\n",
    "    return preds_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test = pd.read_csv(os.path.join(folderPath,'test_set_metadata.csv.zip'),compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13999999999999996\n",
      "0.14\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:37:26,538:main:       50000000 done in   9.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       50000000 done in   9.8\n",
      "0.14\n",
      "0.14\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.14\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.13999999999999999\n",
      "0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 19:51:07,630:main:      100000000 done in  23.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      100000000 done in  23.5\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.14\n",
      "0.14\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.14\n",
      "0.14\n",
      "0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 20:05:14,362:main:      150000000 done in  37.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      150000000 done in  37.6\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.13999999999999996\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.13999999999999999\n",
      "0.13999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 20:19:52,737:main:      200000000 done in  52.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      200000000 done in  52.2\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.13999999999999999\n",
      "0.14000000000000004\n",
      "0.13999999999999999\n",
      "0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 20:34:34,768:main:      250000000 done in  66.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      250000000 done in  66.9\n",
      "0.14000000000000004\n",
      "0.13999999999999999\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.14\n",
      "0.14\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.13999999999999996\n",
      "0.14000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 20:49:09,994:main:      300000000 done in  81.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      300000000 done in  81.5\n",
      "0.14000000000000004\n",
      "0.14000000000000004\n",
      "0.14000000000000004\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.13999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 21:05:03,951:main:      350000000 done in  97.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      350000000 done in  97.4\n",
      "0.14\n",
      "0.13999999999999996\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.13999999999999999\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 21:20:52,682:main:      400000000 done in 113.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      400000000 done in 113.2\n",
      "0.14\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.14\n",
      "0.14\n",
      "0.13999999999999999\n",
      "0.13999999999999999\n",
      "0.14000000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]2018-12-09 21:36:21,813:main:      450000000 done in 128.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      450000000 done in 128.7\n",
      "0.14000000000000004\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "chunks = 5000000\n",
    "remain_df = None\n",
    "    \n",
    "def the_unique(x):\n",
    "    return [x[i] for i in range(len(x)) if x[i] != x[i-1]]\n",
    "\n",
    "for i_c, df in enumerate(pd.read_csv(os.path.join(folderPath,'test_set.csv'), chunksize=chunks, iterator=True)):\n",
    "    # Check object_ids\n",
    "    # I believe np.unique keeps the order of group_ids as they appear in the file\n",
    "    # My belief is wrong (I should have read the doc !)\n",
    "    # A big thank you to https://www.kaggle.com/filby89\n",
    "    # Use .tolist() is almost 3 times faster than the_unique(df['object_id'].values)\n",
    "    unique_ids = the_unique(df['object_id'].tolist())\n",
    "    new_remain_df = df.loc[df['object_id'] == unique_ids[-1]].copy()\n",
    "\n",
    "    if remain_df is None:\n",
    "        df = df.loc[df['object_id'].isin(unique_ids[:-1])].copy()\n",
    "    else:\n",
    "        df = pd.concat([remain_df, df.loc[df['object_id'].isin(unique_ids[:-1])]], axis=0)\n",
    "\n",
    "    # Create remaining samples df\n",
    "    remain_df = new_remain_df\n",
    "\n",
    "    preds_df = predict_chunk(df_=df,\n",
    "                                 clfs_=clfs,\n",
    "                                 meta_=meta_test,\n",
    "                                 features=full_train.columns,\n",
    "                                 train_mean=train_mean)\n",
    "\n",
    "    if i_c == 0:\n",
    "        preds_df.to_csv('predictions_v3.csv', header=True, index=False, float_format='%.6f')\n",
    "    else:\n",
    "        preds_df.to_csv('predictions_v3.csv', header=False, mode='a', index=False, float_format='%.6f')\n",
    "\n",
    "    del preds_df\n",
    "    gc.collect()\n",
    "\n",
    "    if (i_c + 1) % 10 == 0:\n",
    "        get_logger().info('%15d done in %5.1f' % (chunks * (i_c + 1), (time.time() - start) / 60))\n",
    "        print('%15d done in %5.1f' % (chunks * (i_c + 1), (time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14\n"
     ]
    }
   ],
   "source": [
    "preds_df = predict_chunk(df_=remain_df,\n",
    "                             clfs_=clfs,\n",
    "                             meta_=meta_test,\n",
    "                             features=full_train.columns,\n",
    "                             train_mean=train_mean)\n",
    "\n",
    "preds_df.to_csv('predictions_v3.csv', header=False, mode='a', index=False, float_format='%.6f')\n",
    "\n",
    "z = pd.read_csv('predictions_v3.csv')\n",
    "\n",
    "z = z.groupby('object_id').mean()\n",
    "\n",
    "z.to_csv('single_predictions_v3.csv', index=True, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#006064\">3.1. Removing Redundant Columns</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#9575cd'>4. Machine Learning Modelling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#006064\">4.1. Data Pre-processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"#0097a7\">4.1.1 Imputation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"#0097a7\">4.1.2 Labelling of Categorical variables</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"#0097a7\">4.1.3 One Hot Encoder</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=\"#0097a7\">4.1.4 Scaling</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#006064\">4.2 Creating Baseline Model </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#006064\">4.3 Model Selection</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#006064\">4.4 Model Optimization</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#006064\">4.5 Implementation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#9575cd'>5. Investigating Predictions/Evaluation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#9575cd'>6. Submission</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
